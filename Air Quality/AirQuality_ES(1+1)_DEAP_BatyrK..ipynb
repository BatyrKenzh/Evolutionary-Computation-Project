{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ES(1+1) with 1/5 Rule\n",
        "\n",
        "Name: Batyr Kenzheakhmetov"
      ],
      "metadata": {
        "id": "z1od15vVJlIG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUpkbR6Jrtat",
        "outputId": "bb4cc8d6-2172-4453-9f6c-2318d8988393"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "                     CO(GT)  PT08.S1(CO)  NMHC(GT)  C6H6(GT)  PT08.S2(NMHC)  \\\n",
            "DateTime                                                                      \n",
            "2004-03-10 18:00:00     2.6       1360.0     150.0      11.9         1046.0   \n",
            "2004-03-10 19:00:00     2.0       1292.0     112.0       9.4          955.0   \n",
            "2004-03-10 20:00:00     2.2       1402.0      88.0       9.0          939.0   \n",
            "2004-03-10 21:00:00     2.2       1376.0      80.0       9.2          948.0   \n",
            "2004-03-10 22:00:00     1.6       1272.0      51.0       6.5          836.0   \n",
            "2004-03-10 23:00:00     1.2       1197.0      38.0       4.7          750.0   \n",
            "2004-03-11 00:00:00     1.2       1185.0      31.0       3.6          690.0   \n",
            "2004-03-11 01:00:00     1.0       1136.0      31.0       3.3          672.0   \n",
            "2004-03-11 02:00:00     0.9       1094.0      24.0       2.3          609.0   \n",
            "2004-03-11 03:00:00     0.6       1010.0      19.0       1.7          561.0   \n",
            "\n",
            "                     NOx(GT)  PT08.S3(NOx)  NO2(GT)  PT08.S4(NO2)  \\\n",
            "DateTime                                                            \n",
            "2004-03-10 18:00:00    166.0        1056.0    113.0        1692.0   \n",
            "2004-03-10 19:00:00    103.0        1174.0     92.0        1559.0   \n",
            "2004-03-10 20:00:00    131.0        1140.0    114.0        1555.0   \n",
            "2004-03-10 21:00:00    172.0        1092.0    122.0        1584.0   \n",
            "2004-03-10 22:00:00    131.0        1205.0    116.0        1490.0   \n",
            "2004-03-10 23:00:00     89.0        1337.0     96.0        1393.0   \n",
            "2004-03-11 00:00:00     62.0        1462.0     77.0        1333.0   \n",
            "2004-03-11 01:00:00     62.0        1453.0     76.0        1333.0   \n",
            "2004-03-11 02:00:00     45.0        1579.0     60.0        1276.0   \n",
            "2004-03-11 03:00:00   -200.0        1705.0   -200.0        1235.0   \n",
            "\n",
            "                     PT08.S5(O3)     T    RH      AH  \n",
            "DateTime                                              \n",
            "2004-03-10 18:00:00       1268.0  13.6  48.9  0.7578  \n",
            "2004-03-10 19:00:00        972.0  13.3  47.7  0.7255  \n",
            "2004-03-10 20:00:00       1074.0  11.9  54.0  0.7502  \n",
            "2004-03-10 21:00:00       1203.0  11.0  60.0  0.7867  \n",
            "2004-03-10 22:00:00       1110.0  11.2  59.6  0.7888  \n",
            "2004-03-10 23:00:00        949.0  11.2  59.2  0.7848  \n",
            "2004-03-11 00:00:00        733.0  11.3  56.8  0.7603  \n",
            "2004-03-11 01:00:00        730.0  10.7  60.0  0.7702  \n",
            "2004-03-11 02:00:00        620.0  10.7  59.7  0.7648  \n",
            "2004-03-11 03:00:00        501.0  10.3  60.2  0.7517  \n",
            "(7485, 13)\n"
          ]
        }
      ],
      "source": [
        "# import libraries\n",
        "import pandas as pd\n",
        "from statsmodels.tsa.api import VAR\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# load the dataset\n",
        "file_path = '/content/gdrive/My Drive/AirQualityData/AirQualityUCI.csv'\n",
        "data = pd.read_csv(file_path, delimiter=';')\n",
        "\n",
        "# clean numeric columns\n",
        "columns_to_clean = ['CO(GT)', 'C6H6(GT)', 'T', 'RH', 'AH'] # origianl article did not include CO(GT)\n",
        "\n",
        "# replace commas with dots and convert them to numeric\n",
        "for col in columns_to_clean:\n",
        "    data[col] = data[col].str.replace(',', '.')\n",
        "    data[col] = pd.to_numeric(data[col], errors='coerce')\n",
        "\n",
        "# drop the unnamed columns and any rows with missing values\n",
        "data_cleaned = data.drop(columns=['Unnamed: 15', 'Unnamed: 16']).dropna()\n",
        "\n",
        "# convert 'Date' and 'Time' to a single DateTime index <=== Not a colum!!!\n",
        "data_cleaned['DateTime'] = pd.to_datetime(data['Date'] + ' ' + data['Time'], format='%d/%m/%Y %H.%M.%S')\n",
        "data_cleaned = data_cleaned.set_index('DateTime')\n",
        "\n",
        "# drop the 'Date' and 'Time' columns\n",
        "data_cleaned = data_cleaned.drop(columns=['Date', 'Time'])\n",
        "\n",
        "# ensure all columns are numeric\n",
        "data_cleaned = data_cleaned.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# drop rows with NaN\n",
        "data_cleaned = data_cleaned.dropna()\n",
        "\n",
        "# split the data (80% train, 20% test)\n",
        "train_size = int(len(data_cleaned) * 0.8)\n",
        "train_data = data_cleaned[:train_size]\n",
        "test_data = data_cleaned[train_size:]\n",
        "\n",
        "\n",
        "# printing first ten rows\n",
        "print(train_data.head(10))\n",
        "print(train_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data preparation\n",
        "n_lags = 3\n",
        "\n",
        "def create_lagged_features_lstm(data, n_lags):\n",
        "    lagged_data = data.copy()\n",
        "    for i in range(1, n_lags + 1):\n",
        "        lagged_data[f'NOx_lag_{i}'] = lagged_data['NOx(GT)'].shift(i)\n",
        "    lagged_data = lagged_data.dropna() # drop any rows with missing values\n",
        "    return lagged_data\n",
        "\n",
        "# apply lagged feature generation to train_data and test_data\n",
        "train_data_lagged = create_lagged_features_lstm(train_data, n_lags)\n",
        "test_data_lagged = create_lagged_features_lstm(test_data, n_lags)\n",
        "\n",
        "print(train_data_lagged.iloc[0])\n",
        "print(train_data_lagged.shape)\n",
        "# print(test_data_lagged.head())\n",
        "print(test_data_lagged.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbkMN0Saupk7",
        "outputId": "71bd0002-d4aa-408b-a134-f4bf9a0b25c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CO(GT)              2.2000\n",
            "PT08.S1(CO)      1376.0000\n",
            "NMHC(GT)           80.0000\n",
            "C6H6(GT)            9.2000\n",
            "PT08.S2(NMHC)     948.0000\n",
            "NOx(GT)           172.0000\n",
            "PT08.S3(NOx)     1092.0000\n",
            "NO2(GT)           122.0000\n",
            "PT08.S4(NO2)     1584.0000\n",
            "PT08.S5(O3)      1203.0000\n",
            "T                  11.0000\n",
            "RH                 60.0000\n",
            "AH                  0.7867\n",
            "NOx_lag_1         131.0000\n",
            "NOx_lag_2         103.0000\n",
            "NOx_lag_3         166.0000\n",
            "Name: 2004-03-10 21:00:00, dtype: float64\n",
            "(7482, 16)\n",
            "(1869, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# separate X and y\n",
        "X_train_all_features = train_data_lagged.drop(columns=['NOx(GT)']).values  # Use all features\n",
        "y_train = train_data_lagged['NOx(GT)'].values\n",
        "print(X_train_all_features.shape)\n",
        "print(y_train.shape)\n",
        "print(y_train[0:5])\n",
        "print(y_train[-5:])\n",
        "\n",
        "X_test_all_features = test_data_lagged.drop(columns=['NOx(GT)']).values\n",
        "y_test = test_data_lagged['NOx(GT)'].values\n",
        "\n",
        "# reshape data for LSTM (samples, timesteps, features)\n",
        "# //  <--- floor division\n",
        "X_train_lstm_all_features = X_train_all_features.reshape((X_train_all_features.shape[0], n_lags, X_train_all_features.shape[1] // n_lags))\n",
        "X_test_lstm_all_features = X_test_all_features.reshape((X_test_all_features.shape[0], n_lags, X_test_all_features.shape[1] // n_lags))\n",
        "\n",
        "print(X_train_lstm_all_features.shape)\n",
        "print(X_test_lstm_all_features.shape)\n",
        "print(X_train_lstm_all_features[0:2])\n",
        "print(X_train_lstm_all_features[-2:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSjQC9svuvZE",
        "outputId": "e08bdeb8-c4f7-4793-a205-e861ac2712ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7482, 15)\n",
            "(7482,)\n",
            "[172. 131.  89.  62.  62.]\n",
            "[172. 138. 121. 143. 114.]\n",
            "(7482, 3, 5)\n",
            "(1869, 3, 5)\n",
            "[[[2.200e+00 1.376e+03 8.000e+01 9.200e+00 9.480e+02]\n",
            "  [1.092e+03 1.220e+02 1.584e+03 1.203e+03 1.100e+01]\n",
            "  [6.000e+01 7.867e-01 1.310e+02 1.030e+02 1.660e+02]]\n",
            "\n",
            " [[1.600e+00 1.272e+03 5.100e+01 6.500e+00 8.360e+02]\n",
            "  [1.205e+03 1.160e+02 1.490e+03 1.110e+03 1.120e+01]\n",
            "  [5.960e+01 7.888e-01 1.720e+02 1.310e+02 1.030e+02]]]\n",
            "[[[ 1.000e+00  8.660e+02 -2.000e+02  3.000e+00  6.520e+02]\n",
            "  [ 1.060e+03  9.800e+01  8.570e+02  5.730e+02  1.190e+01]\n",
            "  [ 3.080e+01  4.285e-01  1.210e+02  1.380e+02  1.720e+02]]\n",
            "\n",
            " [[ 8.000e-01  8.190e+02 -2.000e+02  1.900e+00  5.760e+02]\n",
            "  [ 1.142e+03  8.500e+01  8.090e+02  4.920e+02  1.140e+01]\n",
            "  [ 3.200e+01  4.310e-01  1.430e+02  1.210e+02  1.380e+02]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Activation, Input\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras import optimizers\n",
        "\n",
        "\n",
        "act_func = ('relu', 'elu')\n",
        "optimz = ('RMSprop', 'Adam')\n",
        "lags = (2, 3, 4, 6)\n",
        "\n",
        "def LSTM_Function(param):\n",
        "    # data preparation\n",
        "    n_lags = lags[int(param[5])]\n",
        "\n",
        "    def create_lagged_features_lstm(data, n_lags):\n",
        "        lagged_data = data.copy()\n",
        "        for i in range(1, n_lags + 1):\n",
        "            lagged_data[f'NOx_lag_{i}'] = lagged_data['NOx(GT)'].shift(i)\n",
        "        lagged_data = lagged_data.dropna() # drop any rows with missing values\n",
        "        return lagged_data\n",
        "\n",
        "\n",
        "    # apply lagged feature generation to train_data and test_data\n",
        "    train_data_lagged = create_lagged_features_lstm(train_data, n_lags)\n",
        "    test_data_lagged = create_lagged_features_lstm(test_data, n_lags)\n",
        "\n",
        "\n",
        "    # separate X and y\n",
        "    X_train_all_features = train_data_lagged.drop(columns=['NOx(GT)']).values  # Use all features\n",
        "    y_train = train_data_lagged['NOx(GT)'].values\n",
        "    X_test_all_features = test_data_lagged.drop(columns=['NOx(GT)']).values\n",
        "    y_test = test_data_lagged['NOx(GT)'].values\n",
        "\n",
        "\n",
        "    # reshape data for LSTM (samples, timesteps, features)\n",
        "    # //  <--- floor division\n",
        "    X_train_lstm_all_features = X_train_all_features.reshape((X_train_all_features.shape[0], n_lags, X_train_all_features.shape[1] // n_lags))\n",
        "    X_test_lstm_all_features = X_test_all_features.reshape((X_test_all_features.shape[0], n_lags, X_test_all_features.shape[1] // n_lags))\n",
        "\n",
        "\n",
        "\n",
        "    # Build the model\n",
        "    model_all_features = Sequential()\n",
        "    model_all_features.add(Input(shape=(n_lags, X_train_lstm_all_features.shape[2])))\n",
        "    model_all_features.add(LSTM(int(param[0]), activation=act_func[int(param[3])]))\n",
        "    model_all_features.add(Dense(1))\n",
        "\n",
        "    # Optimizer selection\n",
        "    if param[4] == 0:\n",
        "        optmzr = optimizers.RMSprop(learning_rate=param[1])\n",
        "    elif param[4] == 1:\n",
        "        optmzr = optimizers.Adam(learning_rate=param[1])\n",
        "\n",
        "    model_all_features.compile(optimizer=optmzr, loss='mse')\n",
        "\n",
        "    # Early stopping\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "    # Train the model\n",
        "    history_all_features = model_all_features.fit(\n",
        "        X_train_lstm_all_features, y_train,\n",
        "        epochs=50, batch_size=int(param[2]),\n",
        "        validation_data=(X_test_lstm_all_features, y_test),\n",
        "        callbacks=[early_stopping], verbose=0\n",
        "    )\n",
        "\n",
        "    # Predict\n",
        "    y_pred_all_features = model_all_features.predict(X_test_lstm_all_features)\n",
        "\n",
        "    # Flatten predictions\n",
        "    y_pred_all_features = y_pred_all_features.flatten()\n",
        "\n",
        "    # Skip trials with NaN predictions\n",
        "    if np.any(np.isnan(y_pred_all_features)):\n",
        "        return float('inf')  # High loss for invalid trials\n",
        "\n",
        "    # Evaluate\n",
        "    rmse_all_features = np.sqrt(mean_squared_error(y_test, y_pred_all_features))\n",
        "\n",
        "    return rmse_all_features\n",
        "\n",
        "\n",
        "\n",
        "# 50 LSTM units, 0.001 learning rate, batch size 32, 'relu' activation (index 0), 'Adam' optimizer (index 1), 3 number of lags (index 1)\n",
        "params = [50, 0.001, 32, 0, 1, 1]  # Example parameters:\n",
        "\n",
        "rmse = LSTM_Function(params)\n",
        "print(f\"RMSE: {rmse}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVE22qWNvwIc",
        "outputId": "d1c9b5c6-f134-4044-d452-f1a5a910712d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            "RMSE: 71.59649357926101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Constants\n",
        "MaxGen = 1000\n",
        "MaxTrial = 5\n",
        "numVar = 6\n",
        "\n",
        "# acceptable range for each hyper parameter\n",
        "low0 = 250  # number of hidden neurons\n",
        "high0 = 350\n",
        "low1  = 0.001 # smallest learning rate\n",
        "high1 = 0.1\n",
        "low2  = 8 # min batch size\n",
        "high2 = 32\n",
        "\n",
        "totgen = 0\n",
        "foundCnt = 0  # acceptable solution found\n",
        "objfunc = LSTM_Function\n",
        "\n",
        "# for 1/5 rule\n",
        "stepSize_i = 0.82 # initial stepsize\n",
        "stepSize_r = 0.82 # stepsize change ratio.\n",
        "                  # 0.82 was used previously by Hans-Paul Schwefel, a PhD student of Rechenberg\n",
        "\n",
        "\n",
        "print(f\"[#neurons, #lags, lr, bsize, actfun, optmzr]\")\n",
        "\n",
        "def print_HP_found(x, eval):\n",
        "  print(f\"#neurons={int(x[0])}, #lags={lags[int(x[5])]}, lr={x[1]:.5f}, bsize={int(x[2])}, actF={act_func[int(x[3])]}, optim={optimz[int(x[4])]}\")\n",
        "  print(f\"RMSE={eval:.5f}\")\n",
        "\n",
        "for trial in range(0, MaxTrial):\n",
        "    xp = np.empty(numVar) # parent\n",
        "    p_val = 0\n",
        "    xo = np.empty(numVar) # offspring\n",
        "    o_val = 0\n",
        "\n",
        "    successCnt = 0;\n",
        "    WindowSize = 10\n",
        "\n",
        "\n",
        "    print(f\"************************** Trial # = {trial+1}\")\n",
        "\n",
        "    # initialize hyper parameters\n",
        "    xp[0] = np.random.randint(low0, high0)\n",
        "    xp[1] = round(np.random.uniform(low1, high1), 5) # init learning rate\n",
        "    xp[2] = 16 # batch size\n",
        "    xp[3] = 0 # sigmoid\n",
        "    xp[4] = 1 # optimizer\n",
        "    xp[5] = 0 # lags\n",
        "\n",
        "    p_val = objfunc(xp)     # evaluate the parent\n",
        "\n",
        "    stepSize = stepSize_i\n",
        "\n",
        "    for g in range(1, MaxGen+1):\n",
        "        if (g % WindowSize) == 0: # update stepsize\n",
        "            if successCnt > (WindowSize * 0.2):\n",
        "                stepSize = stepSize / stepSize_r #increase\n",
        "            elif successCnt < (WindowSize * 0.2):\n",
        "                stepSize = stepSize * stepSize_r #decrease\n",
        "            #else do not change stepSize\n",
        "            #print(successCnt, stepSize)\n",
        "            successCnt = 0\n",
        "\n",
        "        def mutate_activation_function(xp, stepSize):\n",
        "            current_act = int(xp[3])  # Current activation function index\n",
        "            # Calculate the transition index based on step size (cyclical movement)\n",
        "            new_act = (current_act + int(np.sign(np.random.normal(0, stepSize)))) % len(act_func)\n",
        "            xp[3] = new_act\n",
        "            return xp\n",
        "\n",
        "        def mutate_optimizer(xp, stepSize):\n",
        "            current_opt = int(xp[4])  # Current optimizer index\n",
        "            # Calculate the transition index based on step size (cyclical movement)\n",
        "            new_opt = (current_opt + int(np.sign(np.random.normal(0, stepSize)))) % len(optimz)\n",
        "            xp[4] = new_opt\n",
        "            return xp\n",
        "\n",
        "        def mutate_lags_number(xp, stepSize):\n",
        "            current_lags = int(xp[5])  # Current number of lags\n",
        "            # Calculate the transition index based on step size (cyclical movement)\n",
        "            new_lags = (current_lags + int(np.sign(np.random.normal(0, stepSize)))) % len(lags)\n",
        "            xp[5] = new_lags\n",
        "            return xp\n",
        "\n",
        "        # Existing mutation for continuous parameters\n",
        "        def mutate_continuous(x, index, low, high, stepSize):\n",
        "            x[index] = int(x[index] + int(np.round(np.random.normal(0.0, stepSize))))\n",
        "            if x[index] < low: x[index] = low\n",
        "            elif x[index] > high: x[index] = high\n",
        "            return x\n",
        "\n",
        "        def mutate_learning_rate(x, index, low, high, stepSize):\n",
        "            # Add random noise (normal distribution) to the parameter\n",
        "            x[index] = x[index] + np.random.normal(0.0, stepSize)\n",
        "            # Ensure the value stays within bounds\n",
        "            if x[index] < low: x[index] = low\n",
        "            elif x[index] > high: x[index] = high\n",
        "            return x\n",
        "\n",
        "        # def mutate_neurons(x, index, low, high, step_size):\n",
        "        #     # Mutate with a larger step size for neurons\n",
        "        #     x[index] = int(x[index] + int(np.round(np.random.normal(0.0, stepSize))))\n",
        "        #     if x[index] < low:\n",
        "        #         x[index] = low\n",
        "        #     elif x[index] > high:\n",
        "        #         x[index] = high\n",
        "        #     return x\n",
        "\n",
        "        # Example of integrating this into the main loop where we mutate each hyperparameter\n",
        "        def mutate_hyperparameters(xp, stepSize):\n",
        "            # Mutate number of hidden neurons\n",
        "            xp = mutate_continuous(xp, 0, low0, high0, stepSize)\n",
        "\n",
        "            # Mutate learning rate\n",
        "            xp = mutate_learning_rate(xp, 1, low1, high1, stepSize)\n",
        "\n",
        "            # Mutate batch size\n",
        "            xp = mutate_continuous(xp, 2, low2, high2, stepSize)\n",
        "\n",
        "            # Mutate activation function using the custom operator\n",
        "            xp = mutate_activation_function(xp, stepSize)\n",
        "\n",
        "            # Mutate optimizer using the custom operator\n",
        "            xp = mutate_optimizer(xp, stepSize)\n",
        "\n",
        "            # Mutate number of lags\n",
        "            xp = mutate_lags_number(xp, stepSize)\n",
        "\n",
        "            return xp\n",
        "\n",
        "        # Mutate the hyperparameters using the new function\n",
        "        xo = xp.copy()  # create offspring by copying the parent\n",
        "        xo = mutate_hyperparameters(xo, stepSize)  # mutate the offspring\n",
        "\n",
        "        o_val = objfunc(xo)  # evaluate offspring\n",
        "\n",
        "        # select\n",
        "        if o_val < p_val:\n",
        "            #xp = xo # No! must maintain two separate spaces\n",
        "            xp = xo.copy()\n",
        "            p_val = o_val\n",
        "            successCnt += 1;\n",
        "\n",
        "\n",
        "        if p_val < 60: # we assume minima is zero.\n",
        "            print(f\"Acceptable solution found after {g} iterations:\")\n",
        "            #print(f\"{xp}, {p_val:.5f}\")\n",
        "            print_HP_found(xp, p_val)\n",
        "            totgen += g\n",
        "            foundCnt += 1\n",
        "            break # cannot use while since it may not find acceptable minia\n",
        "\n",
        "print(f\"System Success = {foundCnt/MaxTrial*100}%\")\n",
        "totgen += (MaxTrial-foundCnt)*MaxGen\n",
        "print(f\"Avgerage # of generations used = {(totgen/MaxTrial):,.0f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohqL5vYUy6p4",
        "outputId": "8de0aedb-f72b-4471-9758-5a9636bfdd64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[#neurons, #lags, lr, bsize, actfun, optmzr]\n",
            "************************** Trial # = 1\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "Acceptable solution found after 10 iterations:\n",
            "#neurons=332, #lags=4, lr=0.00100, bsize=15, actF=relu, optim=Adam\n",
            "RMSE=53.79395\n",
            "************************** Trial # = 2\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "Acceptable solution found after 12 iterations:\n",
            "#neurons=281, #lags=3, lr=0.00100, bsize=15, actF=elu, optim=RMSprop\n",
            "RMSE=58.37963\n",
            "************************** Trial # = 3\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
            "Acceptable solution found after 6 iterations:\n",
            "#neurons=250, #lags=2, lr=0.00100, bsize=17, actF=relu, optim=Adam\n",
            "RMSE=59.57211\n",
            "************************** Trial # = 4\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "Acceptable solution found after 16 iterations:\n",
            "#neurons=300, #lags=3, lr=0.00100, bsize=15, actF=elu, optim=RMSprop\n",
            "RMSE=57.35670\n",
            "************************** Trial # = 5\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "Acceptable solution found after 4 iterations:\n",
            "#neurons=321, #lags=2, lr=0.00100, bsize=15, actF=relu, optim=Adam\n",
            "RMSE=56.73787\n",
            "System Success = 100.0%\n",
            "Avgerage # of generations used = 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import GRU\n",
        "\n",
        "\n",
        "def GRU_Function(param):\n",
        "    # data preparation\n",
        "    n_lags = lags[int(param[5])]\n",
        "\n",
        "    def create_lagged_features_lstm(data, n_lags):\n",
        "        lagged_data = data.copy()\n",
        "        for i in range(1, n_lags + 1):\n",
        "            lagged_data[f'NOx_lag_{i}'] = lagged_data['NOx(GT)'].shift(i)\n",
        "        lagged_data = lagged_data.dropna() # drop any rows with missing values\n",
        "        return lagged_data\n",
        "\n",
        "\n",
        "    # apply lagged feature generation to train_data and test_data\n",
        "    train_data_lagged = create_lagged_features_lstm(train_data, n_lags)\n",
        "    test_data_lagged = create_lagged_features_lstm(test_data, n_lags)\n",
        "\n",
        "\n",
        "    # separate X and y\n",
        "    X_train_all_features = train_data_lagged.drop(columns=['NOx(GT)']).values  # Use all features\n",
        "    y_train = train_data_lagged['NOx(GT)'].values\n",
        "    X_test_all_features = test_data_lagged.drop(columns=['NOx(GT)']).values\n",
        "    y_test = test_data_lagged['NOx(GT)'].values\n",
        "\n",
        "\n",
        "    # reshape data for LSTM (samples, timesteps, features)\n",
        "    # //  <--- floor division\n",
        "    X_train_lstm_all_features = X_train_all_features.reshape((X_train_all_features.shape[0], n_lags, X_train_all_features.shape[1] // n_lags))\n",
        "    X_test_lstm_all_features = X_test_all_features.reshape((X_test_all_features.shape[0], n_lags, X_test_all_features.shape[1] // n_lags))\n",
        "\n",
        "\n",
        "\n",
        "    # Build the model\n",
        "    model_all_features = Sequential()\n",
        "    model_all_features.add(Input(shape=(n_lags, X_train_lstm_all_features.shape[2])))\n",
        "    model_all_features.add(GRU(int(param[0]), activation=act_func[int(param[3])]))\n",
        "    model_all_features.add(Dense(1))\n",
        "\n",
        "    # Optimizer selection\n",
        "    if param[4] == 0:\n",
        "        optmzr = optimizers.RMSprop(learning_rate=param[1])\n",
        "    elif param[4] == 1:\n",
        "        optmzr = optimizers.Adam(learning_rate=param[1])\n",
        "\n",
        "    model_all_features.compile(optimizer=optmzr, loss='mse')\n",
        "\n",
        "    # Early stopping\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "    # Train the model\n",
        "    history_all_features = model_all_features.fit(\n",
        "        X_train_lstm_all_features, y_train,\n",
        "        epochs=100, batch_size=int(param[2]),\n",
        "        validation_data=(X_test_lstm_all_features, y_test),\n",
        "        callbacks=[early_stopping], verbose=0\n",
        "    )\n",
        "\n",
        "    # Predict\n",
        "    y_pred_all_features = model_all_features.predict(X_test_lstm_all_features)\n",
        "\n",
        "    # Flatten predictions\n",
        "    y_pred_all_features = y_pred_all_features.flatten()\n",
        "\n",
        "    # Skip trials with NaN predictions\n",
        "    if np.any(np.isnan(y_pred_all_features)):\n",
        "        return float('inf')  # High loss for invalid trials\n",
        "\n",
        "    # Evaluate\n",
        "    rmse_all_features = np.sqrt(mean_squared_error(y_test, y_pred_all_features))\n",
        "\n",
        "    return rmse_all_features\n",
        "\n",
        "# Constants\n",
        "MaxGen = 1000\n",
        "MaxTrial = 5\n",
        "numVar = 6\n",
        "\n",
        "# acceptable range for each hyper parameter\n",
        "low0 = 250  # number of hidden neurons\n",
        "high0 = 350\n",
        "low1  = 0.001 # smallest learning rate\n",
        "high1 = 0.1\n",
        "low2  = 8 # min batch size\n",
        "high2 = 32\n",
        "\n",
        "totgen = 0\n",
        "foundCnt = 0  # acceptable solution found\n",
        "\n",
        "# for 1/5 rule\n",
        "stepSize_i = 0.82 # initial stepsize\n",
        "stepSize_r = 0.82 # stepsize change ratio.\n",
        "                  # 0.82 was used previously by Hans-Paul Schwefel, a PhD student of Rechenberg\n",
        "\n",
        "\n",
        "print(f\"[#neurons, #lags, lr, bsize, actfun, optmzr]\")\n",
        "\n",
        "def print_HP_found(x, eval):\n",
        "  print(f\"#neurons={int(x[0])}, #lags={lags[int(x[5])]}, lr={x[1]:.5f}, bsize={int(x[2])}, actF={act_func[int(x[3])]}, optim={optimz[int(x[4])]}\")\n",
        "  print(f\"RMSE={eval:.5f}\")\n",
        "\n",
        "objfunc = GRU_Function\n",
        "\n",
        "for trial in range(0, MaxTrial):\n",
        "    xp = np.empty(numVar) # parent\n",
        "    p_val = 0\n",
        "    xo = np.empty(numVar) # offspring\n",
        "    o_val = 0\n",
        "\n",
        "    successCnt = 0;\n",
        "    WindowSize = 10\n",
        "\n",
        "\n",
        "    print(f\"************************** Trial # = {trial+1}\")\n",
        "\n",
        "    # initialize hyper parameters\n",
        "    xp[0] = np.random.randint(low0, high0)\n",
        "    xp[1] = round(np.random.uniform(low1, high1), 5) # init learning rate\n",
        "    xp[2] = 1 # batch size\n",
        "    xp[3] = 0 # sigmoid\n",
        "    xp[4] = 1 # optimizer\n",
        "    xp[5] = 0 # lags\n",
        "\n",
        "    p_val = objfunc(xp)     # evaluate the parent\n",
        "\n",
        "    stepSize = stepSize_i\n",
        "\n",
        "    for g in range(1, MaxGen+1):\n",
        "        if (g % WindowSize) == 0: # update stepsize\n",
        "            if successCnt > (WindowSize * 0.2):\n",
        "                stepSize = stepSize / stepSize_r #increase\n",
        "            elif successCnt < (WindowSize * 0.2):\n",
        "                stepSize = stepSize * stepSize_r #decrease\n",
        "            #else do not change stepSize\n",
        "            #print(successCnt, stepSize)\n",
        "            successCnt = 0\n",
        "\n",
        "        def mutate_activation_function(xp, stepSize):\n",
        "            current_act = int(xp[3])  # Current activation function index\n",
        "            # Calculate the transition index based on step size (cyclical movement)\n",
        "            new_act = (current_act + int(np.sign(np.random.normal(0, stepSize)))) % len(act_func)\n",
        "            xp[3] = new_act\n",
        "            return xp\n",
        "\n",
        "        def mutate_optimizer(xp, stepSize):\n",
        "            current_opt = int(xp[4])  # Current optimizer index\n",
        "            # Calculate the transition index based on step size (cyclical movement)\n",
        "            new_opt = (current_opt + int(np.sign(np.random.normal(0, stepSize)))) % len(optimz)\n",
        "            xp[4] = new_opt\n",
        "            return xp\n",
        "\n",
        "        def mutate_lags_number(xp, stepSize):\n",
        "            current_lags = int(xp[5])  # Current number of lags\n",
        "            # Calculate the transition index based on step size (cyclical movement)\n",
        "            new_lags = (current_lags + int(np.sign(np.random.normal(0, stepSize)))) % len(lags)\n",
        "            xp[5] = new_lags\n",
        "            return xp\n",
        "\n",
        "        # Existing mutation for continuous parameters\n",
        "        def mutate_continuous(x, index, low, high, stepSize):\n",
        "            x[index] = int(x[index] + int(np.round(np.random.normal(0.0, stepSize))))\n",
        "            if x[index] < low: x[index] = low\n",
        "            elif x[index] > high: x[index] = high\n",
        "            return x\n",
        "\n",
        "        def mutate_learning_rate(x, index, low, high, stepSize):\n",
        "            # Add random noise (normal distribution) to the parameter\n",
        "            x[index] = x[index] + np.random.normal(0.0, stepSize)\n",
        "            # Ensure the value stays within bounds\n",
        "            if x[index] < low: x[index] = low\n",
        "            elif x[index] > high: x[index] = high\n",
        "            return x\n",
        "\n",
        "        # def mutate_neurons(x, index, low, high, step_size):\n",
        "        #     # Mutate with a larger step size for neurons\n",
        "        #     x[index] = int(x[index] + int(np.round(np.random.normal(0.0, stepSize))))\n",
        "        #     if x[index] < low:\n",
        "        #         x[index] = low\n",
        "        #     elif x[index] > high:\n",
        "        #         x[index] = high\n",
        "        #     return x\n",
        "\n",
        "        # Example of integrating this into the main loop where we mutate each hyperparameter\n",
        "        def mutate_hyperparameters(xp, stepSize):\n",
        "            # Mutate number of hidden neurons\n",
        "            xp = mutate_continuous(xp, 0, low0, high0, stepSize)\n",
        "\n",
        "            # Mutate learning rate\n",
        "            xp = mutate_learning_rate(xp, 1, low1, high1, stepSize)\n",
        "\n",
        "            # Mutate batch size\n",
        "            xp = mutate_continuous(xp, 2, low2, high2, stepSize)\n",
        "\n",
        "            # Mutate activation function using the custom operator\n",
        "            xp = mutate_activation_function(xp, stepSize)\n",
        "\n",
        "            # Mutate optimizer using the custom operator\n",
        "            xp = mutate_optimizer(xp, stepSize)\n",
        "\n",
        "            # Mutate number of lags\n",
        "            xp = mutate_lags_number(xp, stepSize)\n",
        "\n",
        "            return xp\n",
        "\n",
        "        # Mutate the hyperparameters using the new function\n",
        "        xo = xp.copy()  # create offspring by copying the parent\n",
        "        xo = mutate_hyperparameters(xo, stepSize)  # mutate the offspring\n",
        "\n",
        "        o_val = objfunc(xo)  # evaluate offspring\n",
        "\n",
        "        # select\n",
        "        if o_val < p_val:\n",
        "            #xp = xo # No! must maintain two separate spaces\n",
        "            xp = xo.copy()\n",
        "            p_val = o_val\n",
        "            successCnt += 1;\n",
        "\n",
        "\n",
        "        if p_val < 60: # we assume minima is zero.\n",
        "            print(f\"Acceptable solution found after {g} iterations:\")\n",
        "            #print(f\"{xp}, {p_val:.5f}\")\n",
        "            print_HP_found(xp, p_val)\n",
        "            totgen += g\n",
        "            foundCnt += 1\n",
        "            break # cannot use while since it may not find acceptable minia\n",
        "\n",
        "print(f\"System Success = {foundCnt/MaxTrial*100}%\")\n",
        "totgen += (MaxTrial-foundCnt)*MaxGen\n",
        "print(f\"Avgerage # of generations used = {(totgen/MaxTrial):,.0f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IM7m2nqlN0g",
        "outputId": "c985e662-b723-431d-99aa-ec38c3c13e28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[#neurons, #lags, lr, bsize, actfun, optmzr]\n",
            "************************** Trial # = 1\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "Acceptable solution found after 11 iterations:\n",
            "#neurons=301, #lags=3, lr=0.00100, bsize=8, actF=elu, optim=RMSprop\n",
            "RMSE=57.95436\n",
            "************************** Trial # = 2\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "Acceptable solution found after 7 iterations:\n",
            "#neurons=311, #lags=3, lr=0.00100, bsize=8, actF=elu, optim=RMSprop\n",
            "RMSE=57.83578\n",
            "************************** Trial # = 3\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
            "Acceptable solution found after 11 iterations:\n",
            "#neurons=342, #lags=2, lr=0.00100, bsize=8, actF=relu, optim=Adam\n",
            "RMSE=59.98334\n",
            "************************** Trial # = 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Updated Data based on Trial Results\n",
        "data = {\n",
        "    \"Trial #\": [1, 2, 3, 4, 5, 1, 2, 3, 4, 5],\n",
        "    \"System\": [\"LSTM\", \"LSTM\", \"LSTM\", \"LSTM\", \"LSTM\", \"GRU\", \"GRU\", \"GRU\", \"GRU\", \"GRU\"],\n",
        "    \"# neurons\": [332, 281, 250, 300, 321, 283, 287, 250, 328, 286],\n",
        "    \"# lags\": [4, 3, 2, 3, 2, 3, 6, 3, 3, 3],\n",
        "    \"Learning rate\": [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001],\n",
        "    \"Batch size\": [15, 15, 17, 15, 15, 10, 8, 11, 8, 8],\n",
        "    \"Activation function\": [\"relu\", \"elu\", \"relu\", \"elu\", \"relu\", \"elu\", \"elu\", \"elu\", \"elu\", \"elu\"],\n",
        "    \"Optimizer\": [\"Adam\", \"RMSprop\", \"Adam\", \"RMSprop\", \"Adam\", \"RMSprop\", \"RMSprop\", \"RMSprop\", \"RMSprop\", \"RMSprop\"],\n",
        "    \"Loss\": [\n",
        "        53.79395, 58.37963, 59.57211, 57.35670, 56.73787,\n",
        "        59.09231, 59.30344, 56.83308, 58.47610, 59.76044\n",
        "    ],\n",
        "    \"Iterations\": [10, 12, 6, 16, 4, 7, 2, 7, 2, 4],\n",
        "}\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Style and display the DataFrame\n",
        "styled_df = df.style.set_properties(\n",
        "    **{'background-color': '#b3d9ff', 'color': 'black', 'border-color': 'black'}\n",
        ")\n",
        "styled_df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "NWkhxYWJo9ju",
        "outputId": "298eb29a-37fe-415b-8277-e61871df12ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7e1d9e9c25f0>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_0343c_row0_col0, #T_0343c_row0_col1, #T_0343c_row0_col2, #T_0343c_row0_col3, #T_0343c_row0_col4, #T_0343c_row0_col5, #T_0343c_row0_col6, #T_0343c_row0_col7, #T_0343c_row0_col8, #T_0343c_row0_col9, #T_0343c_row1_col0, #T_0343c_row1_col1, #T_0343c_row1_col2, #T_0343c_row1_col3, #T_0343c_row1_col4, #T_0343c_row1_col5, #T_0343c_row1_col6, #T_0343c_row1_col7, #T_0343c_row1_col8, #T_0343c_row1_col9, #T_0343c_row2_col0, #T_0343c_row2_col1, #T_0343c_row2_col2, #T_0343c_row2_col3, #T_0343c_row2_col4, #T_0343c_row2_col5, #T_0343c_row2_col6, #T_0343c_row2_col7, #T_0343c_row2_col8, #T_0343c_row2_col9, #T_0343c_row3_col0, #T_0343c_row3_col1, #T_0343c_row3_col2, #T_0343c_row3_col3, #T_0343c_row3_col4, #T_0343c_row3_col5, #T_0343c_row3_col6, #T_0343c_row3_col7, #T_0343c_row3_col8, #T_0343c_row3_col9, #T_0343c_row4_col0, #T_0343c_row4_col1, #T_0343c_row4_col2, #T_0343c_row4_col3, #T_0343c_row4_col4, #T_0343c_row4_col5, #T_0343c_row4_col6, #T_0343c_row4_col7, #T_0343c_row4_col8, #T_0343c_row4_col9, #T_0343c_row5_col0, #T_0343c_row5_col1, #T_0343c_row5_col2, #T_0343c_row5_col3, #T_0343c_row5_col4, #T_0343c_row5_col5, #T_0343c_row5_col6, #T_0343c_row5_col7, #T_0343c_row5_col8, #T_0343c_row5_col9, #T_0343c_row6_col0, #T_0343c_row6_col1, #T_0343c_row6_col2, #T_0343c_row6_col3, #T_0343c_row6_col4, #T_0343c_row6_col5, #T_0343c_row6_col6, #T_0343c_row6_col7, #T_0343c_row6_col8, #T_0343c_row6_col9, #T_0343c_row7_col0, #T_0343c_row7_col1, #T_0343c_row7_col2, #T_0343c_row7_col3, #T_0343c_row7_col4, #T_0343c_row7_col5, #T_0343c_row7_col6, #T_0343c_row7_col7, #T_0343c_row7_col8, #T_0343c_row7_col9, #T_0343c_row8_col0, #T_0343c_row8_col1, #T_0343c_row8_col2, #T_0343c_row8_col3, #T_0343c_row8_col4, #T_0343c_row8_col5, #T_0343c_row8_col6, #T_0343c_row8_col7, #T_0343c_row8_col8, #T_0343c_row8_col9, #T_0343c_row9_col0, #T_0343c_row9_col1, #T_0343c_row9_col2, #T_0343c_row9_col3, #T_0343c_row9_col4, #T_0343c_row9_col5, #T_0343c_row9_col6, #T_0343c_row9_col7, #T_0343c_row9_col8, #T_0343c_row9_col9 {\n",
              "  background-color: #b3d9ff;\n",
              "  color: black;\n",
              "  border-color: black;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_0343c\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_0343c_level0_col0\" class=\"col_heading level0 col0\" >Trial #</th>\n",
              "      <th id=\"T_0343c_level0_col1\" class=\"col_heading level0 col1\" >System</th>\n",
              "      <th id=\"T_0343c_level0_col2\" class=\"col_heading level0 col2\" ># neurons</th>\n",
              "      <th id=\"T_0343c_level0_col3\" class=\"col_heading level0 col3\" ># lags</th>\n",
              "      <th id=\"T_0343c_level0_col4\" class=\"col_heading level0 col4\" >Learning rate</th>\n",
              "      <th id=\"T_0343c_level0_col5\" class=\"col_heading level0 col5\" >Batch size</th>\n",
              "      <th id=\"T_0343c_level0_col6\" class=\"col_heading level0 col6\" >Activation function</th>\n",
              "      <th id=\"T_0343c_level0_col7\" class=\"col_heading level0 col7\" >Optimizer</th>\n",
              "      <th id=\"T_0343c_level0_col8\" class=\"col_heading level0 col8\" >Loss</th>\n",
              "      <th id=\"T_0343c_level0_col9\" class=\"col_heading level0 col9\" >Iterations</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_0343c_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_0343c_row0_col0\" class=\"data row0 col0\" >1</td>\n",
              "      <td id=\"T_0343c_row0_col1\" class=\"data row0 col1\" >LSTM</td>\n",
              "      <td id=\"T_0343c_row0_col2\" class=\"data row0 col2\" >332</td>\n",
              "      <td id=\"T_0343c_row0_col3\" class=\"data row0 col3\" >4</td>\n",
              "      <td id=\"T_0343c_row0_col4\" class=\"data row0 col4\" >0.001000</td>\n",
              "      <td id=\"T_0343c_row0_col5\" class=\"data row0 col5\" >15</td>\n",
              "      <td id=\"T_0343c_row0_col6\" class=\"data row0 col6\" >relu</td>\n",
              "      <td id=\"T_0343c_row0_col7\" class=\"data row0 col7\" >Adam</td>\n",
              "      <td id=\"T_0343c_row0_col8\" class=\"data row0 col8\" >53.793950</td>\n",
              "      <td id=\"T_0343c_row0_col9\" class=\"data row0 col9\" >10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_0343c_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_0343c_row1_col0\" class=\"data row1 col0\" >2</td>\n",
              "      <td id=\"T_0343c_row1_col1\" class=\"data row1 col1\" >LSTM</td>\n",
              "      <td id=\"T_0343c_row1_col2\" class=\"data row1 col2\" >281</td>\n",
              "      <td id=\"T_0343c_row1_col3\" class=\"data row1 col3\" >3</td>\n",
              "      <td id=\"T_0343c_row1_col4\" class=\"data row1 col4\" >0.001000</td>\n",
              "      <td id=\"T_0343c_row1_col5\" class=\"data row1 col5\" >15</td>\n",
              "      <td id=\"T_0343c_row1_col6\" class=\"data row1 col6\" >elu</td>\n",
              "      <td id=\"T_0343c_row1_col7\" class=\"data row1 col7\" >RMSprop</td>\n",
              "      <td id=\"T_0343c_row1_col8\" class=\"data row1 col8\" >58.379630</td>\n",
              "      <td id=\"T_0343c_row1_col9\" class=\"data row1 col9\" >12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_0343c_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_0343c_row2_col0\" class=\"data row2 col0\" >3</td>\n",
              "      <td id=\"T_0343c_row2_col1\" class=\"data row2 col1\" >LSTM</td>\n",
              "      <td id=\"T_0343c_row2_col2\" class=\"data row2 col2\" >250</td>\n",
              "      <td id=\"T_0343c_row2_col3\" class=\"data row2 col3\" >2</td>\n",
              "      <td id=\"T_0343c_row2_col4\" class=\"data row2 col4\" >0.001000</td>\n",
              "      <td id=\"T_0343c_row2_col5\" class=\"data row2 col5\" >17</td>\n",
              "      <td id=\"T_0343c_row2_col6\" class=\"data row2 col6\" >relu</td>\n",
              "      <td id=\"T_0343c_row2_col7\" class=\"data row2 col7\" >Adam</td>\n",
              "      <td id=\"T_0343c_row2_col8\" class=\"data row2 col8\" >59.572110</td>\n",
              "      <td id=\"T_0343c_row2_col9\" class=\"data row2 col9\" >6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_0343c_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_0343c_row3_col0\" class=\"data row3 col0\" >4</td>\n",
              "      <td id=\"T_0343c_row3_col1\" class=\"data row3 col1\" >LSTM</td>\n",
              "      <td id=\"T_0343c_row3_col2\" class=\"data row3 col2\" >300</td>\n",
              "      <td id=\"T_0343c_row3_col3\" class=\"data row3 col3\" >3</td>\n",
              "      <td id=\"T_0343c_row3_col4\" class=\"data row3 col4\" >0.001000</td>\n",
              "      <td id=\"T_0343c_row3_col5\" class=\"data row3 col5\" >15</td>\n",
              "      <td id=\"T_0343c_row3_col6\" class=\"data row3 col6\" >elu</td>\n",
              "      <td id=\"T_0343c_row3_col7\" class=\"data row3 col7\" >RMSprop</td>\n",
              "      <td id=\"T_0343c_row3_col8\" class=\"data row3 col8\" >57.356700</td>\n",
              "      <td id=\"T_0343c_row3_col9\" class=\"data row3 col9\" >16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_0343c_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_0343c_row4_col0\" class=\"data row4 col0\" >5</td>\n",
              "      <td id=\"T_0343c_row4_col1\" class=\"data row4 col1\" >LSTM</td>\n",
              "      <td id=\"T_0343c_row4_col2\" class=\"data row4 col2\" >321</td>\n",
              "      <td id=\"T_0343c_row4_col3\" class=\"data row4 col3\" >2</td>\n",
              "      <td id=\"T_0343c_row4_col4\" class=\"data row4 col4\" >0.001000</td>\n",
              "      <td id=\"T_0343c_row4_col5\" class=\"data row4 col5\" >15</td>\n",
              "      <td id=\"T_0343c_row4_col6\" class=\"data row4 col6\" >relu</td>\n",
              "      <td id=\"T_0343c_row4_col7\" class=\"data row4 col7\" >Adam</td>\n",
              "      <td id=\"T_0343c_row4_col8\" class=\"data row4 col8\" >56.737870</td>\n",
              "      <td id=\"T_0343c_row4_col9\" class=\"data row4 col9\" >4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_0343c_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "      <td id=\"T_0343c_row5_col0\" class=\"data row5 col0\" >1</td>\n",
              "      <td id=\"T_0343c_row5_col1\" class=\"data row5 col1\" >GRU</td>\n",
              "      <td id=\"T_0343c_row5_col2\" class=\"data row5 col2\" >283</td>\n",
              "      <td id=\"T_0343c_row5_col3\" class=\"data row5 col3\" >3</td>\n",
              "      <td id=\"T_0343c_row5_col4\" class=\"data row5 col4\" >0.001000</td>\n",
              "      <td id=\"T_0343c_row5_col5\" class=\"data row5 col5\" >10</td>\n",
              "      <td id=\"T_0343c_row5_col6\" class=\"data row5 col6\" >elu</td>\n",
              "      <td id=\"T_0343c_row5_col7\" class=\"data row5 col7\" >RMSprop</td>\n",
              "      <td id=\"T_0343c_row5_col8\" class=\"data row5 col8\" >59.092310</td>\n",
              "      <td id=\"T_0343c_row5_col9\" class=\"data row5 col9\" >7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_0343c_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "      <td id=\"T_0343c_row6_col0\" class=\"data row6 col0\" >2</td>\n",
              "      <td id=\"T_0343c_row6_col1\" class=\"data row6 col1\" >GRU</td>\n",
              "      <td id=\"T_0343c_row6_col2\" class=\"data row6 col2\" >287</td>\n",
              "      <td id=\"T_0343c_row6_col3\" class=\"data row6 col3\" >6</td>\n",
              "      <td id=\"T_0343c_row6_col4\" class=\"data row6 col4\" >0.001000</td>\n",
              "      <td id=\"T_0343c_row6_col5\" class=\"data row6 col5\" >8</td>\n",
              "      <td id=\"T_0343c_row6_col6\" class=\"data row6 col6\" >elu</td>\n",
              "      <td id=\"T_0343c_row6_col7\" class=\"data row6 col7\" >RMSprop</td>\n",
              "      <td id=\"T_0343c_row6_col8\" class=\"data row6 col8\" >59.303440</td>\n",
              "      <td id=\"T_0343c_row6_col9\" class=\"data row6 col9\" >2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_0343c_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "      <td id=\"T_0343c_row7_col0\" class=\"data row7 col0\" >3</td>\n",
              "      <td id=\"T_0343c_row7_col1\" class=\"data row7 col1\" >GRU</td>\n",
              "      <td id=\"T_0343c_row7_col2\" class=\"data row7 col2\" >250</td>\n",
              "      <td id=\"T_0343c_row7_col3\" class=\"data row7 col3\" >3</td>\n",
              "      <td id=\"T_0343c_row7_col4\" class=\"data row7 col4\" >0.001000</td>\n",
              "      <td id=\"T_0343c_row7_col5\" class=\"data row7 col5\" >11</td>\n",
              "      <td id=\"T_0343c_row7_col6\" class=\"data row7 col6\" >elu</td>\n",
              "      <td id=\"T_0343c_row7_col7\" class=\"data row7 col7\" >RMSprop</td>\n",
              "      <td id=\"T_0343c_row7_col8\" class=\"data row7 col8\" >56.833080</td>\n",
              "      <td id=\"T_0343c_row7_col9\" class=\"data row7 col9\" >7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_0343c_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "      <td id=\"T_0343c_row8_col0\" class=\"data row8 col0\" >4</td>\n",
              "      <td id=\"T_0343c_row8_col1\" class=\"data row8 col1\" >GRU</td>\n",
              "      <td id=\"T_0343c_row8_col2\" class=\"data row8 col2\" >328</td>\n",
              "      <td id=\"T_0343c_row8_col3\" class=\"data row8 col3\" >3</td>\n",
              "      <td id=\"T_0343c_row8_col4\" class=\"data row8 col4\" >0.001000</td>\n",
              "      <td id=\"T_0343c_row8_col5\" class=\"data row8 col5\" >8</td>\n",
              "      <td id=\"T_0343c_row8_col6\" class=\"data row8 col6\" >elu</td>\n",
              "      <td id=\"T_0343c_row8_col7\" class=\"data row8 col7\" >RMSprop</td>\n",
              "      <td id=\"T_0343c_row8_col8\" class=\"data row8 col8\" >58.476100</td>\n",
              "      <td id=\"T_0343c_row8_col9\" class=\"data row8 col9\" >2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_0343c_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "      <td id=\"T_0343c_row9_col0\" class=\"data row9 col0\" >5</td>\n",
              "      <td id=\"T_0343c_row9_col1\" class=\"data row9 col1\" >GRU</td>\n",
              "      <td id=\"T_0343c_row9_col2\" class=\"data row9 col2\" >286</td>\n",
              "      <td id=\"T_0343c_row9_col3\" class=\"data row9 col3\" >3</td>\n",
              "      <td id=\"T_0343c_row9_col4\" class=\"data row9 col4\" >0.001000</td>\n",
              "      <td id=\"T_0343c_row9_col5\" class=\"data row9 col5\" >8</td>\n",
              "      <td id=\"T_0343c_row9_col6\" class=\"data row9 col6\" >elu</td>\n",
              "      <td id=\"T_0343c_row9_col7\" class=\"data row9 col7\" >RMSprop</td>\n",
              "      <td id=\"T_0343c_row9_col8\" class=\"data row9 col8\" >59.760440</td>\n",
              "      <td id=\"T_0343c_row9_col9\" class=\"data row9 col9\" >4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DEAP Framework\n",
        "\n",
        "Name: Batyr Kenzheakhmetov\n",
        "\n",
        "The provided code implements a pipeline to forecast air quality metrics using LSTM models. It encompasses data preprocessing, feature engineering, and hyperparameter optimization through DEAP's evolutionary algorithm. This report evaluates the code, identifies its strengths, and suggests improvements for enhanced efficiency and scalability.\n",
        "\n"
      ],
      "metadata": {
        "id": "zOqQxCW8IVul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deap"
      ],
      "metadata": {
        "id": "aTEnlKYXCF_w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c1fff2a-ca67-41b4-8aed-49991748f164"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deap\n",
            "  Downloading deap-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deap) (1.26.4)\n",
            "Downloading deap-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (135 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/135.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m133.1/135.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.4/135.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: deap\n",
            "Successfully installed deap-1.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from deap import base, creator, tools, algorithms\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import drive, files\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "# Clean up any pre-existing DEAP classes\n",
        "if \"FitnessMin\" in creator.__dict__:\n",
        "    del creator.FitnessMin\n",
        "if \"Individual\" in creator.__dict__:\n",
        "    del creator.Individual\n",
        "\n",
        "from google.colab import drive, files\n",
        "import pandas as pd\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Specify file path\n",
        "file_path = '/content/gdrive/My Drive/DL_data/airQualityUCI/AirQualityUCI.xlsx'\n",
        "\n",
        "# Verify if file exists; if not, upload manually\n",
        "import os\n",
        "if not os.path.exists(file_path):\n",
        "    print(\"File not found. Please upload the file.\")\n",
        "    uploaded = files.upload()\n",
        "    file_path = list(uploaded.keys())[0]\n",
        "\n",
        "# Load the dataset from Excel\n",
        "try:\n",
        "    data = pd.read_excel(file_path)\n",
        "    print(\"File loaded successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading file: {e}\")\n",
        "    raise e\n",
        "\n",
        "# Clean numeric columns\n",
        "columns_to_clean = ['CO(GT)', 'C6H6(GT)', 'T', 'RH', 'AH']\n",
        "for col in columns_to_clean:\n",
        "    if col in data.columns and data[col].dtype == 'object':  # Apply replacement only to string columns\n",
        "        data[col] = data[col].str.replace(',', '.')\n",
        "    data[col] = pd.to_numeric(data[col], errors='coerce')\n",
        "\n",
        "# Drop unnecessary columns\n",
        "data_cleaned = data.drop(columns=['Unnamed: 15', 'Unnamed: 16'], errors='ignore').dropna()\n",
        "\n",
        "# Add DateTime index\n",
        "if 'Date' in data.columns and 'Time' in data.columns:\n",
        "    # Ensure 'Date' and 'Time' are strings before concatenation\n",
        "    data['Date'] = data['Date'].astype(str)\n",
        "    data['Time'] = data['Time'].astype(str)\n",
        "    data_cleaned['DateTime'] = pd.to_datetime(\n",
        "        data['Date'] + ' ' + data['Time'], format='%d/%m/%Y %H.%M.%S', errors='coerce'\n",
        "    )\n",
        "    data_cleaned = data_cleaned.set_index('DateTime').drop(columns=['Date', 'Time'], errors='ignore')\n",
        "else:\n",
        "    print(\"Error: 'Date' or 'Time' column is missing in the dataset.\")\n",
        "\n",
        "# Drop any rows with NaN\n",
        "data_cleaned = data_cleaned.dropna()\n",
        "\n",
        "print(\"Data successfully loaded and cleaned!\")\n",
        "\n",
        "\n",
        "# Train-test split\n",
        "train_size = int(len(data_cleaned) * 0.8)\n",
        "train_data = data_cleaned[:train_size]\n",
        "test_data = data_cleaned[train_size:]\n",
        "\n",
        "# Create lagged features\n",
        "n_lags = 3\n",
        "\n",
        "def create_lagged_features_lstm(data, n_lags):\n",
        "    lagged_data = data.copy()\n",
        "    for i in range(1, n_lags + 1):\n",
        "        lagged_data[f'NOx_lag_{i}'] = lagged_data['NOx(GT)'].shift(i)\n",
        "    lagged_data = lagged_data.dropna()\n",
        "    return lagged_data\n",
        "\n",
        "train_data_lagged = create_lagged_features_lstm(train_data, n_lags)\n",
        "test_data_lagged = create_lagged_features_lstm(test_data, n_lags)\n",
        "\n",
        "# Debug lagged data shapes\n",
        "print(f\"Train data lagged shape: {train_data_lagged.shape}\")\n",
        "print(f\"Test data lagged shape: {test_data_lagged.shape}\")\n",
        "\n",
        "# Ensure lagged features are sufficient\n",
        "if len(train_data_lagged) < n_lags or len(test_data_lagged) < n_lags:\n",
        "    raise ValueError(\"Not enough data points after creating lagged features!\")\n",
        "\n",
        "X_train_all_features = train_data_lagged.drop(columns=['NOx(GT)']).values\n",
        "y_train = train_data_lagged['NOx(GT)'].values\n",
        "X_test_all_features = test_data_lagged.drop(columns=['NOx(GT)']).values\n",
        "y_test = test_data_lagged['NOx(GT)'].values\n",
        "\n",
        "# Debug feature shapes\n",
        "print(f\"X_train_all_features shape: {X_train_all_features.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"X_test_all_features shape: {X_test_all_features.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")\n",
        "\n",
        "# Reshape for LSTM\n",
        "try:\n",
        "    X_train_lstm_all_features = X_train_all_features.reshape(\n",
        "        (X_train_all_features.shape[0], n_lags, -1)\n",
        "    )\n",
        "    X_test_lstm_all_features = X_test_all_features.reshape(\n",
        "        (X_test_all_features.shape[0], n_lags, -1)\n",
        "    )\n",
        "except ValueError as e:\n",
        "    print(\"Error in reshaping data. Check dimensions:\")\n",
        "    print(f\"X_train_all_features shape: {X_train_all_features.shape}\")\n",
        "    print(f\"X_test_all_features shape: {X_test_all_features.shape}\")\n",
        "    raise e\n",
        "\n",
        "# Debug LSTM input shapes\n",
        "print(f\"X_train_lstm_all_features shape: {X_train_lstm_all_features.shape}\")\n",
        "print(f\"X_test_lstm_all_features shape: {X_test_lstm_all_features.shape}\")\n",
        "\n",
        "# Define bounds for hyperparameters\n",
        "LOW = [10, 8, 0.0001]  # [num_neurons, batch_size, learning_rate]\n",
        "HIGH = [350, 64, 0.01]  # [num_neurons, batch_size, learning_rate]\n",
        "N_VAR = len(LOW)\n",
        "\n",
        "# Create DEAP structures\n",
        "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
        "creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
        "\n",
        "toolbox = base.Toolbox()\n",
        "toolbox.register(\"attr_float\", random.uniform, LOW[0], HIGH[0])  # num_neurons\n",
        "toolbox.register(\"attr_int\", random.randint, LOW[1], HIGH[1])    # batch_size\n",
        "toolbox.register(\"attr_lr\", random.uniform, LOW[2], HIGH[2])     # learning_rate\n",
        "toolbox.register(\"individual\", tools.initCycle, creator.Individual,\n",
        "                 (toolbox.attr_float, toolbox.attr_int, toolbox.attr_lr), n=1)\n",
        "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "\n",
        "def eval_function(params):\n",
        "    num_neurons = int(params[0])\n",
        "    batch_size = int(params[1])\n",
        "    learning_rate = params[2]\n",
        "\n",
        "    # Validate and clip batch_size\n",
        "    if batch_size > X_train_lstm_all_features.shape[0]:\n",
        "        batch_size = X_train_lstm_all_features.shape[0]\n",
        "    if batch_size <= 0 or num_neurons <= 0:\n",
        "        raise ValueError(f\"Invalid parameters: batch_size={batch_size}, num_neurons={num_neurons}\")\n",
        "\n",
        "    # Build LSTM model\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(n_lags, X_train_lstm_all_features.shape[2])))\n",
        "    model.add(LSTM(num_neurons, activation='relu'))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')\n",
        "\n",
        "    # Train model\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "    try:\n",
        "        model.fit(X_train_lstm_all_features, y_train, epochs=50, batch_size=batch_size,\n",
        "                  validation_data=(X_test_lstm_all_features, y_test), callbacks=[early_stopping], verbose=0)\n",
        "    except ValueError as e:\n",
        "        print(f\"Error during model training: {e}\")\n",
        "        raise e\n",
        "\n",
        "    # Evaluate model\n",
        "    try:\n",
        "        y_pred = model.predict(X_test_lstm_all_features, verbose=0)\n",
        "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    except ValueError as e:\n",
        "        print(f\"Error during model evaluation: {e}\")\n",
        "        raise e\n",
        "\n",
        "    return (rmse,)\n",
        "\n",
        "\n",
        "\n",
        "toolbox.register(\"evaluate\", eval_function)\n",
        "toolbox.register(\"mate\", tools.cxBlend, alpha=0.5)\n",
        "toolbox.register(\"mutate\", tools.mutGaussian, mu=0, sigma=5, indpb=0.2)\n",
        "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
        "\n",
        "def check_bounds(ind):\n",
        "    ind[0] = np.clip(ind[0], LOW[0], HIGH[0])  # num_neurons\n",
        "    ind[1] = int(np.clip(ind[1], LOW[1], min(HIGH[1], X_train_lstm_all_features.shape[0])))  # batch_size\n",
        "    ind[2] = np.clip(ind[2], LOW[2], HIGH[2])  # learning_rate\n",
        "    return ind\n",
        "\n",
        "\n",
        "toolbox.decorate(\"mutate\", tools.DeltaPenalty(check_bounds, 0))\n",
        "toolbox.decorate(\"evaluate\", tools.DeltaPenalty(check_bounds, 1e6))  # Large penalty for invalid bounds\n",
        "\n",
        "\n",
        "def main():\n",
        "    random.seed(42)\n",
        "    population = toolbox.population(n=10)\n",
        "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
        "    stats.register(\"min\", min)\n",
        "    stats.register(\"avg\", lambda lst: sum(x[0] for x in lst) / len(lst))\n",
        "\n",
        "    population, logbook = algorithms.eaSimple(population, toolbox,\n",
        "                                              cxpb=0.5, mutpb=0.3,\n",
        "                                              ngen=10, stats=stats, verbose=True)\n",
        "    return population, logbook\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    final_population, log = main()\n",
        "    best_ind = tools.selBest(final_population, k=1)[0]\n",
        "    print(\"Best Hyperparameters:\", best_ind)\n",
        "    print(\"Best RMSE:\", best_ind.fitness.values[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "id": "s4MR1deiHM-D",
        "outputId": "a42cac8f-5b23-4eb3-f8e4-300f70260db3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "File not found. Please upload the file.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b8b334a8-d454-4204-9ebe-53a144fb25d3\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b8b334a8-d454-4204-9ebe-53a144fb25d3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving AirQualityUCI.xlsx to AirQualityUCI (10).xlsx\n",
            "File loaded successfully!\n",
            "Data successfully loaded and cleaned!\n",
            "Train data lagged shape: (7482, 16)\n",
            "Test data lagged shape: (1869, 16)\n",
            "X_train_all_features shape: (7482, 15)\n",
            "y_train shape: (7482,)\n",
            "X_test_all_features shape: (1869, 15)\n",
            "y_test shape: (1869,)\n",
            "X_train_lstm_all_features shape: (7482, 3, 5)\n",
            "X_test_lstm_all_features shape: (1869, 3, 5)\n",
            "gen\tnevals\tmin                  \tavg    \n",
            "0  \t10    \t(60.950659438551476,)\t64.5736\n",
            "1  \t9     \t(59.8708588878189,)  \t64.5623\n",
            "2  \t8     \t(57.0934037094124,)  \t62.8934\n",
            "3  \t7     \t(58.75785169945173,) \t65.9198\n",
            "4  \t4     \t(57.60017500686971,) \t61.2761\n",
            "5  \t8     \t(59.39399326396649,) \t63.1094\n",
            "6  \t2     \t(59.39399326396649,) \t62.9521\n",
            "7  \t4     \t(59.70544978798159,) \t63.9952\n",
            "8  \t6     \t(54.16794761420757,) \t61.9871\n",
            "9  \t8     \t(58.61185314159118,) \t63.5496\n",
            "10 \t4     \t(58.61185314159118,) \t61.8251\n",
            "Best Hyperparameters: [343.922567069387, 44, 0.001955849498299081]\n",
            "Best RMSE: 58.61185314159118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'log' is the logbook from the previous code\n",
        "gen = log.select(\"gen\")\n",
        "fit_mins = log.select(\"min\")\n",
        "fit_avgs = log.select(\"avg\")\n",
        "\n",
        "plt.plot(gen, fit_mins, label=\"Minimum Fitness\")\n",
        "#plt.plot(gen, fit_avgs, label=\"Average Fitness\")\n",
        "plt.xlabel(\"Generation\")\n",
        "plt.ylabel(\"Fitness\")\n",
        "plt.title(\"Fitness over Generations\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "31HYs76eWJBO",
        "outputId": "b4bb5880-c955-45c9-fdcf-dc71095f2136"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}